{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLN86sfM_M6M"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/cookbooks/GraphRAG_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhKmG4Pz_M6Q"
      },
      "source": [
        "# GraphRAG Implementation with LlamaIndex\n",
        "\n",
        "[GraphRAG (Graphs + Retrieval Augmented Generation)](https://www.microsoft.com/en-us/research/project/graphrag/) combines the strengths of Retrieval Augmented Generation (RAG) and Query-Focused Summarization (QFS) to effectively handle complex queries over large text datasets. While RAG excels in fetching precise information, it struggles with broader queries that require thematic understanding, a challenge that QFS addresses but cannot scale well. GraphRAG integrates these approaches to offer responsive and thorough querying capabilities across extensive, diverse text corpora.\n",
        "\n",
        "\n",
        "This notebook provides guidance on constructing the GraphRAG pipeline using the LlamaIndex PropertyGraph abstractions.\n",
        "\n",
        "\n",
        "**NOTE:** This is an approximate implementation of GraphRAG. We are currently developing a series of cookbooks that will detail the exact implementation of GraphRAG."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-k2ODki_M6R"
      },
      "source": [
        "## GraphRAG Aproach\n",
        "\n",
        "The GraphRAG involves two steps:\n",
        "\n",
        "1. Graph Generation - Creates Graph, builds communities and its summaries over the given document.\n",
        "2. Answer to the Query - Use summaries of the communities created from step-1 to answer the query.\n",
        "\n",
        "**Graph Generation:**\n",
        "\n",
        "1. **Source Documents to Text Chunks:** Source documents are divided into smaller text chunks for easier processing.\n",
        "\n",
        "2. **Text Chunks to Element Instances:** Each text chunk is analyzed to identify and extract entities and relationships, resulting in a list of tuples that represent these elements.\n",
        "\n",
        "3. **Element Instances to Element Summaries:** The extracted entities and relationships are summarized into descriptive text blocks for each element using the LLM.\n",
        "\n",
        "4. **Element Summaries to Graph Communities:** These entities, relationships and summaries form a graph, which is subsequently partitioned into communities using algorithms using Heirarchical Leiden to establish a hierarchical structure.\n",
        "\n",
        "5. **Graph Communities to Community Summaries:** The LLM generates summaries for each community, providing insights into the dataset’s overall topical structure and semantics.\n",
        "\n",
        "**Answering the Query:**\n",
        "\n",
        "**Community Summaries to Global Answers:** The summaries of the communities are utilized to respond to user queries. This involves generating intermediate answers, which are then consolidated into a comprehensive global answer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsjOF2re_M6S"
      },
      "source": [
        "## GraphRAG Pipeline Components\n",
        "\n",
        "Here are the different components we implemented to build all of the processes mentioned above.\n",
        "\n",
        "1. **Source Documents to Text Chunks:** Implemented using `SentenceSplitter` with a chunk size of 1024 and chunk overlap of 20 tokens.\n",
        "\n",
        "2. **Text Chunks to Element Instances AND Element Instances to Element Summaries:** Implemented using `GraphRAGExtractor`.\n",
        "\n",
        "3. **Element Summaries to Graph Communities AND Graph Communities to Community Summaries:** Implemented using `GraphRAGStore`.\n",
        "\n",
        "4. **Community Summaries to Global Answers:** Implemented using `GraphQueryEngine`.\n",
        "\n",
        "\n",
        "Let's check into each of these components and build GraphRAG pipeline.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV2Ub4GO_M6S"
      },
      "source": [
        "## Installation\n",
        "\n",
        "`graspologic` is used to use hierarchical_leiden for building communities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s9kLoLE4_M6T",
        "outputId": "403f4f20-d0db-4c1b-ca0d-1fb1368f5794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.11.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graspologic\n",
            "  Downloading graspologic-3.4.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting scipy==1.12.0\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
            "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.13 (from llama-index)\n",
            "  Downloading llama_index_core-0.11.13.post1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.9 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting POT<0.10,>=0.9 (from graspologic)\n",
            "  Downloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Collecting anytree<3.0.0,>=2.12.1 (from graspologic)\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting beartype<0.19.0,>=0.18.5 (from graspologic)\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.2 in /usr/local/lib/python3.10/dist-packages (from graspologic) (4.3.3)\n",
            "Collecting graspologic-native<2.0.0,>=1.2.1 (from graspologic)\n",
            "  Downloading graspologic_native-1.2.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting hyppo<0.5.0,>=0.4.0 (from graspologic)\n",
            "  Downloading hyppo-0.4.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from graspologic) (1.4.2)\n",
            "Collecting matplotlib<4.0.0,>=3.8.4 (from graspologic)\n",
            "  Downloading matplotlib-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx<4,>=3 in /usr/local/lib/python3.10/dist-packages (from graspologic) (3.3)\n",
            "INFO: pip is looking at multiple versions of graspologic to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting graspologic\n",
            "  Downloading graspologic-3.4.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting POT<0.8.0,>=0.7.0 (from graspologic)\n",
            "  Downloading POT-0.7.0.post1.tar.gz (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype<0.11.0,>=0.10.4 (from graspologic)\n",
            "  Downloading beartype-0.10.4-py3-none-any.whl.metadata (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyppo<0.4.0,>=0.3.2 (from graspologic)\n",
            "  Downloading hyppo-0.3.2.tar.gz (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx<3.0.0,>=2.8.8 (from graspologic)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting graspologic\n",
            "  Downloading graspologic-3.3.0.tar.gz (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting beartype>=0.10.0 (from graspologic)\n",
            "  Downloading beartype-0.19.0-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyppo>=0.3.2 (from graspologic)\n",
            "  Downloading hyppo-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: matplotlib!=3.3.*,!=3.6.1,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from graspologic) (3.7.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from graspologic) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from graspologic) (1.5.2)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from graspologic) (0.14.3)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from graspologic) (4.12.2)\n",
            "Collecting umap-learn>=0.4.6 (from graspologic)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree<3.0.0,>=2.12.1->graspologic) (1.16.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.2->graspologic) (7.0.4)\n",
            "Requirement already satisfied: numba>=0.46 in /usr/local/lib/python3.10/dist-packages (from hyppo>=0.3.2->graspologic) (0.60.0)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.10/dist-packages (from hyppo>=0.3.2->graspologic) (1.7.0)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
            "  Downloading openai-1.48.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.13->llama-index) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (3.10.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (2.9.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (4.66.5)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.13->llama-index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
            "  Downloading llama_cloud-0.1.0-py3-none-any.whl.metadata (750 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
            "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.3.*,!=3.6.1,>=3.0.0->graspologic) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->graspologic) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->graspologic) (0.5.6)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.4.6->graspologic)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.13->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.13->llama-index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.13->llama-index) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.13->llama-index) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.13->llama-index) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.46->hyppo>=0.3.2->graspologic) (0.43.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.13->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.13->llama-index) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.13->llama-index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.13->llama-index) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.13->llama-index) (3.1.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.13->llama-index)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.12.0,>=0.11.13->llama-index) (1.2.2)\n",
            "Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.11.13-py3-none-any.whl (6.8 kB)\n",
            "Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.19.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graspologic_native-1.2.1-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hyppo-0.5.0-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.3/165.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.13.post1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.9-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading POT-0.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (835 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m835.4/835.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading llama_cloud-0.1.0-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.6-py3-none-any.whl (10 kB)\n",
            "Downloading openai-1.48.0-py3-none-any.whl (376 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: graspologic\n",
            "  Building wheel for graspologic (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graspologic: filename=graspologic-3.3.0-py3-none-any.whl size=5201794 sha256=46770f5592e46ae97cb2d72214123d73f98e84fe3944eb8e11532d36641d6cef\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/d1/8c/f371fb5cb6f387cbe0af31a94158fa55ecfd837daaf3b2a213\n",
            "Successfully built graspologic\n",
            "Installing collected packages: striprtf, dirtyjson, tenacity, pypdf, numpy, nltk, mypy-extensions, marshmallow, jiter, h11, graspologic-native, deprecated, beartype, anytree, typing-inspect, tiktoken, scipy, httpcore, POT, httpx, dataclasses-json, pynndescent, openai, llama-index-core, llama-cloud, hyppo, umap-learn, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, graspologic, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n",
            "pandas-stubs 2.1.4.231227 requires numpy>=1.26.0; python_version < \"3.13\", but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed POT-0.9.4 anytree-2.12.1 beartype-0.19.0 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 graspologic-3.3.0 graspologic-native-1.2.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 hyppo-0.5.0 jiter-0.5.0 llama-cloud-0.1.0 llama-index-0.11.13 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.13.post1 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.9 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.6 marshmallow-3.22.0 mypy-extensions-1.0.0 nltk-3.9.1 numpy-1.24.4 openai-1.48.0 pynndescent-0.5.13 pypdf-4.3.1 scipy-1.12.0 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0 umap-learn-0.5.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "86adc3e1a78841dca31e48c75c09d4f8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install llama-index graspologic numpy==1.24.4 scipy==1.12.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2bToJlB_M6U"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "We will use a sample news article dataset retrieved from Diffbot, which Tomaz has conveniently made available on GitHub for easy access.\n",
        "\n",
        "The dataset contains 2,500 samples; for ease of experimentation, we will use 50 of these samples, which include the `title` and `text` of news articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9DtL9f5m_M6U",
        "outputId": "7c712d3c-fb11-44b1-f406-a76e9ec5fbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0                             Chevron: Best Of Breed   \n",
              "1       FirstEnergy (NYSE:FE) Posts Earnings Results   \n",
              "2  Dáil almost suspended after Sinn Féin TD put p...   \n",
              "3  Epic’s latest tool can animate hyperrealistic ...   \n",
              "4  EU to Ban Huawei, ZTE from Internal Commission...   \n",
              "\n",
              "                                  date  \\\n",
              "0  2031-04-06T01:36:32.000000000+00:00   \n",
              "1  2030-04-29T06:55:28.000000000+00:00   \n",
              "2  2023-06-15T14:32:11.000000000+00:00   \n",
              "3  2023-06-15T14:00:00.000000000+00:00   \n",
              "4  2023-06-15T13:50:00.000000000+00:00   \n",
              "\n",
              "                                                text  \n",
              "0  JHVEPhoto Like many companies in the O&G secto...  \n",
              "1  FirstEnergy (NYSE:FE – Get Rating) posted its ...  \n",
              "2  The Dáil was almost suspended on Thursday afte...  \n",
              "3  Today, Epic is releasing a new tool designed t...  \n",
              "4  The European Commission is planning to ban equ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1465e6cb-de89-4369-b6f4-9d0f24176ca6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chevron: Best Of Breed</td>\n",
              "      <td>2031-04-06T01:36:32.000000000+00:00</td>\n",
              "      <td>JHVEPhoto Like many companies in the O&amp;G secto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FirstEnergy (NYSE:FE) Posts Earnings Results</td>\n",
              "      <td>2030-04-29T06:55:28.000000000+00:00</td>\n",
              "      <td>FirstEnergy (NYSE:FE – Get Rating) posted its ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dáil almost suspended after Sinn Féin TD put p...</td>\n",
              "      <td>2023-06-15T14:32:11.000000000+00:00</td>\n",
              "      <td>The Dáil was almost suspended on Thursday afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Epic’s latest tool can animate hyperrealistic ...</td>\n",
              "      <td>2023-06-15T14:00:00.000000000+00:00</td>\n",
              "      <td>Today, Epic is releasing a new tool designed t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EU to Ban Huawei, ZTE from Internal Commission...</td>\n",
              "      <td>2023-06-15T13:50:00.000000000+00:00</td>\n",
              "      <td>The European Commission is planning to ban equ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1465e6cb-de89-4369-b6f4-9d0f24176ca6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1465e6cb-de89-4369-b6f4-9d0f24176ca6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1465e6cb-de89-4369-b6f4-9d0f24176ca6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-404e84fe-5fcc-4999-bc8a-9d4036cee7f4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-404e84fe-5fcc-4999-bc8a-9d4036cee7f4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-404e84fe-5fcc-4999-bc8a-9d4036cee7f4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "news",
              "summary": "{\n  \"name\": \"news\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"NFL Rumors: What Patriots \\u2018Made Clear\\u2019 To DeAndre Hopkins\\u2019 Reps\",\n          \"Stellantis to close Illinois assembly plant, lay off workers\",\n          \"Uber to shut food delivery business in Italy, exit Israel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"2023-06-15T12:14:00.000000000+00:00\",\n          \"2023-06-15T12:11:00.000000000+00:00\",\n          \"2023-06-15T13:50:00.000000000+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"The Patriots apparently didn\\u2019t waste any time courting DeAndre Hopkins once he hit the open market.\\nHopkins officially became an NFL free agent when he was released by the Arizona Cardinals on May 26. Around that juncture, New England reportedly reached out to the star wide receiver\\u2019s team to express interest. Those conversations birthed a free-agent visit, which reportedly started Wednesday in Foxboro, Mass. and carried into Thursday morning.\\n\\u201cI just got official word: DeAndre Hopkins is in New England,\\u201d NFL insider Jeremy Fowler said Thursday on ESPN\\u2019s \\u201cGet Up.\\u201d \\u201cHe\\u2019s meeting with the Patriots. He will meet with the coaches, Bill Belichick. The Patriots\\u2019 interest remains high. They made that clear with Hopkins\\u2019 representatives from the very beginning when he became a free agent. So, we\\u2019ll see if they can close on this thing.\\u201d\\nHopkins has received co-signs from New England team leaders like Mac Jones and Matthew Judon, and the Patriots reportedly are optimistic they can add the five-time Pro Bowl selection. But even if Hopkins\\u2019 meeting with the Patriots goes well, don\\u2019t be surprised if the 31-year-old leaves New England without a deal.\\n\\u201cI\\u2019m also told Hopkins (is) not in a major rush,\\u201d Fowler said. \\u201cHe\\u2019s looking at more of training camp, even early August as more of a harder deadline for him to sign somewhere. So, it would have to be a very sweet offer for New England to make that happen today.\\u201d\\nThe Patriots appear to be the second team Hopkins met with as a free agent. Prior to his trip to New England, the veteran pass-catcher talked shop with the Titans in Nashville.\",\n          \"Generation Investment Management, an investment management firm, released its \\u201cGlobal Equity Strategy\\u201d first quarter 2023 investor letter. A copy of the same can be downloaded here. The strategy performed roughly in line with the benchmark on a rolling five-year net basis and it is about 1.3% below on a rolling three-year net basis. The main reasons for the underperformance of the strategy were overestimation of the quality of the holdings, change in the external environment, and overpayment for some companies. In addition, you can check the top 5 holdings of the fund to know its best picks in 2023.\\nGeneration Investment Management Global Equity Strategy highlighted stocks like Henry Schein, Inc. (NASDAQ:HSIC) in the first quarter 2023 investor letter. Headquartered in Melville, New York, Henry Schein, Inc. (NASDAQ:HSIC) is a healthcare products and services provider to medical, dental, and veterinary office-based practitioners. On June 14, 2023, Henry Schein, Inc. (NASDAQ:HSIC) stock closed at $74.81 per share. One-month return of Henry Schein, Inc. (NASDAQ:HSIC) was -2.27%, and its shares gained 2.24% of their value over the last 52 weeks. Henry Schein, Inc. (NASDAQ:HSIC) has a market capitalization of $9.8 billion.\\nGeneration Investment Management Global Equity Strategy made the following comment about Henry Schein, Inc. (NASDAQ:HSIC) in its first quarter 2023 investor letter:\\n\\\"We continue to evaluate new investment opportunities. Despite the volatility of recent months, we see a number of strong tailwinds in certain sectors \\u2014 particularly those that solve big societal problems. One such problem is growing healthcare costs, which will put more pressure on social-security systems and household budgets. Later in this letter we profile Henry Schein, Inc. (NASDAQ:HSIC), the largest distributor of dental and medical products and services globally. Companies like Henry Schein have the potential to control the growth in healthcare costs, while promoting access to underserved communities.\\nAt the same time, healthcare cost pressures are escalating. To make matters worse, healthcare has worse labour shortages than most industries, while productivity improvements are hard to come by.4 In almost every country, health spending is forecast to form an increasing share of GDP in the coming years.\\nAt Generation, we look for companies that can provide a solution to these long-term challenges. More specifically, we look for healthcare companies that reduce costs and drive efficiency; that improve clinical outcomes; and that improve access to care. Henry Schein, a long-term holding of your portfolio, is an example of a company that we believe can deliver on all three of these criteria...\\\" (Click here to read the full text)\\nHenry Schein, Inc. (NASDAQ:HSIC) is not on our list of . As per our database, 28 hedge fund portfolios held Henry Schein, Inc. (NASDAQ:HSIC) at the end of first quarter 2023 which was 30 in the previous quarter.\\nWe discussed Henry Schein, Inc. (NASDAQ:HSIC) in and shared the list of top gainers on November 1, 2022. In addition, please check out our page for more investor letters from hedge funds and other leading investors.\\nDisclosure: None. This article is originally published at .\",\n          \"Manchester City will begin their bid for a record fourth consecutive Premier League title away to Vincent Kompany\\u2019s Burnley.\\nThe Treble winners will visit Turf Moor to face their former captain\\u2019s newly-promoted side on the evening of Friday, August 11 to raise the curtain on the 2023-24 campaign.\\nIt will be the second time Kompany \\u2013 who won the title on four occasions as City skipper \\u2013 will have faced his old side as a manager, with City running out 6-0 winners at the Etihad in March\\u2019s FA Cup quarter-final.\\nPremier League debutants Luton will play their first top-flight fixture since 1992 away to Roberto De Zerbi\\u2019s Brighton on Saturday, August 12, having to wait until the following weekend for their first home game when Kenilworth Road will become the smallest ground to host a fixture in the competition for the visit of Burnley.\\nThe other promoted side Sheffield United kick off their season with a home game against Crystal Palace.\\nThe outstanding fixture of the opening weekend will be at Stamford Bridge where Mauricio Pochettino begins life as Chelsea manager against Liverpool on Sunday, August 13, with both sides looking to bounce back after disappointing campaigns.\\nFollow live updates and reaction below\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from llama_index.core import Document\n",
        "\n",
        "news = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\"\n",
        ")[:50]\n",
        "\n",
        "news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDXTdVVX_M6V"
      },
      "source": [
        "Prepare documents as required by LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yuP_Eq_s_M6V"
      },
      "outputs": [],
      "source": [
        "documents = [\n",
        "    Document(text=f\"{row['title']}: {row['text']}\")\n",
        "    for i, row in news.iterrows()\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2otoQLY_M6V"
      },
      "source": [
        "## Setup API Key and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c3VLakRb_M6V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"<Enter Your Key Dude>\"\n",
        "\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "llm = OpenAI(model=\"gpt-4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IeqNOXW_M6W"
      },
      "source": [
        "## GraphRAGExtractor\n",
        "\n",
        "The GraphRAGExtractor class is designed to extract triples (subject-relation-object) from text and enrich them by adding descriptions for entities and relationships to their properties using an LLM.\n",
        "\n",
        "This functionality is similar to that of the `SimpleLLMPathExtractor`, but includes additional enhancements to handle entity, relationship descriptions. For guidance on implementation, you may look at similar existing [extractors](https://docs.llamaindex.ai/en/latest/examples/property_graph/Dynamic_KG_Extraction/?h=comparing).\n",
        "\n",
        "Here's a breakdown of its functionality:\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "1. `llm:` The language model used for extraction.\n",
        "2. `extract_prompt:` A prompt template used to guide the LLM in extracting information.\n",
        "3. `parse_fn:` A function to parse the LLM's output into structured data.\n",
        "4. `max_paths_per_chunk:` Limits the number of triples extracted per text chunk.\n",
        "5. `num_workers:` For parallel processing of multiple text nodes.\n",
        "\n",
        "\n",
        "**Main Methods:**\n",
        "\n",
        "1. `__call__:` The entry point for processing a list of text nodes.\n",
        "2. `acall:` An asynchronous version of __call__ for improved performance.\n",
        "3. `_aextract:` The core method that processes each individual node.\n",
        "\n",
        "\n",
        "**Extraction Process:**\n",
        "\n",
        "For each input node (chunk of text):\n",
        "1. It sends the text to the LLM along with the extraction prompt.\n",
        "2. The LLM's response is parsed to extract entities, relationships, descriptions for entities and relations.\n",
        "3. Entities are converted into EntityNode objects. Entity description is stored in metadata\n",
        "4. Relationships are converted into Relation objects. Relationship description is stored in metadata.\n",
        "5. These are added to the node's metadata under KG_NODES_KEY and KG_RELATIONS_KEY.\n",
        "\n",
        "**NOTE:** In the current implementation, we are using only relationship descriptions. In the next implementation, we will utilize entity descriptions during the retrieval stage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PX6C2uu7_M6W"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from typing import Any, List, Callable, Optional, Union, Dict\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "from llama_index.core.async_utils import run_jobs\n",
        "from llama_index.core.indices.property_graph.utils import (\n",
        "    default_parse_triplets_fn,\n",
        ")\n",
        "from llama_index.core.graph_stores.types import (\n",
        "    EntityNode,\n",
        "    KG_NODES_KEY,\n",
        "    KG_RELATIONS_KEY,\n",
        "    Relation,\n",
        ")\n",
        "from llama_index.core.llms.llm import LLM\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "from llama_index.core.prompts.default_prompts import (\n",
        "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
        ")\n",
        "from llama_index.core.schema import TransformComponent, BaseNode\n",
        "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class GraphRAGExtractor(TransformComponent):\n",
        "    \"\"\"Extract triples from a graph.\n",
        "\n",
        "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
        "\n",
        "    Args:\n",
        "        llm (LLM):\n",
        "            The language model to use.\n",
        "        extract_prompt (Union[str, PromptTemplate]):\n",
        "            The prompt to use for extracting triples.\n",
        "        parse_fn (callable):\n",
        "            A function to parse the output of the language model.\n",
        "        num_workers (int):\n",
        "            The number of workers to use for parallel processing.\n",
        "        max_paths_per_chunk (int):\n",
        "            The maximum number of paths to extract per chunk.\n",
        "    \"\"\"\n",
        "\n",
        "    llm: LLM\n",
        "    extract_prompt: PromptTemplate\n",
        "    parse_fn: Callable\n",
        "    num_workers: int\n",
        "    max_paths_per_chunk: int\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm: Optional[LLM] = None,\n",
        "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
        "        parse_fn: Callable = default_parse_triplets_fn,\n",
        "        max_paths_per_chunk: int = 10,\n",
        "        num_workers: int = 4,\n",
        "    ) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        from llama_index.core import Settings\n",
        "\n",
        "        if isinstance(extract_prompt, str):\n",
        "            extract_prompt = PromptTemplate(extract_prompt)\n",
        "\n",
        "        super().__init__(\n",
        "            llm=llm or Settings.llm,\n",
        "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
        "            parse_fn=parse_fn,\n",
        "            num_workers=num_workers,\n",
        "            max_paths_per_chunk=max_paths_per_chunk,\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def class_name(cls) -> str:\n",
        "        return \"GraphExtractor\"\n",
        "\n",
        "    def __call__(\n",
        "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
        "    ) -> List[BaseNode]:\n",
        "        \"\"\"Extract triples from nodes.\"\"\"\n",
        "        return asyncio.run(\n",
        "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
        "        )\n",
        "\n",
        "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
        "        \"\"\"Extract triples from a node.\"\"\"\n",
        "        assert hasattr(node, \"text\")\n",
        "\n",
        "        text = node.get_content(metadata_mode=\"llm\")\n",
        "        try:\n",
        "            llm_response = await self.llm.apredict(\n",
        "                self.extract_prompt,\n",
        "                text=text,\n",
        "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
        "            )\n",
        "            entities, entities_relationship = self.parse_fn(llm_response)\n",
        "        except ValueError:\n",
        "            entities = []\n",
        "            entities_relationship = []\n",
        "\n",
        "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
        "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
        "        metadata = node.metadata.copy()\n",
        "        for entity, entity_type, description in entities:\n",
        "            metadata[\n",
        "                \"entity_description\"\n",
        "            ] = description  # Not used in the current implementation. But will be useful in future work.\n",
        "            entity_node = EntityNode(\n",
        "                name=entity, label=entity_type, properties=metadata\n",
        "            )\n",
        "            existing_nodes.append(entity_node)\n",
        "\n",
        "        metadata = node.metadata.copy()\n",
        "        for triple in entities_relationship:\n",
        "            subj, rel, obj, description = triple\n",
        "            subj_node = EntityNode(name=subj, properties=metadata)\n",
        "            obj_node = EntityNode(name=obj, properties=metadata)\n",
        "            metadata[\"relationship_description\"] = description\n",
        "            rel_node = Relation(\n",
        "                label=rel,\n",
        "                source_id=subj_node.id,\n",
        "                target_id=obj_node.id,\n",
        "                properties=metadata,\n",
        "            )\n",
        "\n",
        "            existing_nodes.extend([subj_node, obj_node])\n",
        "            existing_relations.append(rel_node)\n",
        "\n",
        "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
        "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
        "        return node\n",
        "\n",
        "    async def acall(\n",
        "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
        "    ) -> List[BaseNode]:\n",
        "        \"\"\"Extract triples from nodes async.\"\"\"\n",
        "        jobs = []\n",
        "        for node in nodes:\n",
        "            jobs.append(self._aextract(node))\n",
        "\n",
        "        return await run_jobs(\n",
        "            jobs,\n",
        "            workers=self.num_workers,\n",
        "            show_progress=show_progress,\n",
        "            desc=\"Extracting paths from text\",\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ4GWgi6_M6W"
      },
      "source": [
        "## GraphRAGStore\n",
        "\n",
        "The `GraphRAGStore` class is an extension of the `SimplePropertyGraphStore `class, designed to implement GraphRAG pipeline. Here's a breakdown of its key components and functions:\n",
        "\n",
        "\n",
        "The class uses community detection algorithms to group related nodes in the graph and then it generates summaries for each community using an LLM.\n",
        "\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "`build_communities():`\n",
        "\n",
        "1. Converts the internal graph representation to a NetworkX graph.\n",
        "\n",
        "2. Applies the hierarchical Leiden algorithm for community detection.\n",
        "\n",
        "3. Collects detailed information about each community.\n",
        "\n",
        "4. Generates summaries for each community.\n",
        "\n",
        "`generate_community_summary(text):`\n",
        "\n",
        "1. Uses LLM to generate a summary of the relationships in a community.\n",
        "2. The summary includes entity names and a synthesis of relationship descriptions.\n",
        "\n",
        "`_create_nx_graph():`\n",
        "\n",
        "1. Converts the internal graph representation to a NetworkX graph for community detection.\n",
        "\n",
        "`_collect_community_info(nx_graph, clusters):`\n",
        "\n",
        "1. Collects detailed information about each node based on its community.\n",
        "2. Creates a string representation of each relationship within a community.\n",
        "\n",
        "`_summarize_communities(community_info):`\n",
        "\n",
        "1. Generates and stores summaries for each community using LLM.\n",
        "\n",
        "`get_community_summaries():`\n",
        "\n",
        "1. Returns the community summaries by building them if not already done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G13GMPhL_M6W"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from llama_index.core.graph_stores import SimplePropertyGraphStore\n",
        "import networkx as nx\n",
        "from graspologic.partition import hierarchical_leiden\n",
        "\n",
        "from llama_index.core.llms import ChatMessage\n",
        "\n",
        "\n",
        "class GraphRAGStore(SimplePropertyGraphStore):\n",
        "    community_summary = {}\n",
        "    max_cluster_size = 5\n",
        "\n",
        "    def generate_community_summary(self, text):\n",
        "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
        "        messages = [\n",
        "            ChatMessage(\n",
        "                role=\"system\",\n",
        "                content=(\n",
        "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
        "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
        "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
        "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
        "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
        "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
        "                ),\n",
        "            ),\n",
        "            ChatMessage(role=\"user\", content=text),\n",
        "        ]\n",
        "        response = OpenAI().chat(messages)\n",
        "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
        "        return clean_response\n",
        "\n",
        "    def build_communities(self):\n",
        "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
        "        nx_graph = self._create_nx_graph()\n",
        "        community_hierarchical_clusters = hierarchical_leiden(\n",
        "            nx_graph, max_cluster_size=self.max_cluster_size\n",
        "        )\n",
        "        community_info = self._collect_community_info(\n",
        "            nx_graph, community_hierarchical_clusters\n",
        "        )\n",
        "        self._summarize_communities(community_info)\n",
        "\n",
        "    def _create_nx_graph(self):\n",
        "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
        "        nx_graph = nx.Graph()\n",
        "        for node in self.graph.nodes.values():\n",
        "            nx_graph.add_node(str(node))\n",
        "        for relation in self.graph.relations.values():\n",
        "            nx_graph.add_edge(\n",
        "                relation.source_id,\n",
        "                relation.target_id,\n",
        "                relationship=relation.label,\n",
        "                description=relation.properties[\"relationship_description\"],\n",
        "            )\n",
        "        return nx_graph\n",
        "\n",
        "    def _collect_community_info(self, nx_graph, clusters):\n",
        "        \"\"\"Collect detailed information for each node based on their community.\"\"\"\n",
        "        community_mapping = {item.node: item.cluster for item in clusters}\n",
        "        community_info = {}\n",
        "        for item in clusters:\n",
        "            cluster_id = item.cluster\n",
        "            node = item.node\n",
        "            if cluster_id not in community_info:\n",
        "                community_info[cluster_id] = []\n",
        "\n",
        "            for neighbor in nx_graph.neighbors(node):\n",
        "                if community_mapping[neighbor] == cluster_id:\n",
        "                    edge_data = nx_graph.get_edge_data(node, neighbor)\n",
        "                    if edge_data:\n",
        "                        detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
        "                        community_info[cluster_id].append(detail)\n",
        "        return community_info\n",
        "\n",
        "    def _summarize_communities(self, community_info):\n",
        "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
        "        for community_id, details in community_info.items():\n",
        "            details_text = (\n",
        "                \"\\n\".join(details) + \".\"\n",
        "            )  # Ensure it ends with a period\n",
        "            self.community_summary[\n",
        "                community_id\n",
        "            ] = self.generate_community_summary(details_text)\n",
        "\n",
        "    def get_community_summaries(self):\n",
        "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
        "        if not self.community_summary:\n",
        "            self.build_communities()\n",
        "        return self.community_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRcwJSBe_M6W"
      },
      "source": [
        "## GraphRAGQueryEngine\n",
        "\n",
        "The GraphRAGQueryEngine class is a custom query engine designed to process queries using the GraphRAG approach. It leverages the community summaries generated by the GraphRAGStore to answer user queries. Here's a breakdown of its functionality:\n",
        "\n",
        "**Main Components:**\n",
        "\n",
        "`graph_store:` An instance of GraphRAGStore, which contains the community summaries.\n",
        "`llm:` A Language Model (LLM) used for generating and aggregating answers.\n",
        "\n",
        "\n",
        "**Key Methods:**\n",
        "\n",
        "`custom_query(query_str: str)`\n",
        "\n",
        "1. This is the main entry point for processing a query. It retrieves community summaries, generates answers from each summary, and then aggregates these answers into a final response.\n",
        "\n",
        "`generate_answer_from_summary(community_summary, query):`\n",
        "\n",
        "1. Generates an answer for the query based on a single community summary.\n",
        "Uses the LLM to interpret the community summary in the context of the query.\n",
        "\n",
        "`aggregate_answers(community_answers):`\n",
        "\n",
        "1. Combines individual answers from different communities into a coherent final response.\n",
        "2. Uses the LLM to synthesize multiple perspectives into a single, concise answer.\n",
        "\n",
        "\n",
        "**Query Processing Flow:**\n",
        "\n",
        "1. Retrieve community summaries from the graph store.\n",
        "2. For each community summary, generate a specific answer to the query.\n",
        "3. Aggregate all community-specific answers into a final, coherent response.\n",
        "\n",
        "\n",
        "**Example usage:**\n",
        "\n",
        "```\n",
        "query_engine = GraphRAGQueryEngine(graph_store=graph_store, llm=llm)\n",
        "\n",
        "response = query_engine.query(\"query\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FotoDHQM_M6X"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.query_engine import CustomQueryEngine\n",
        "from llama_index.core.llms import LLM\n",
        "\n",
        "\n",
        "class GraphRAGQueryEngine(CustomQueryEngine):\n",
        "    graph_store: GraphRAGStore\n",
        "    llm: LLM\n",
        "\n",
        "    def custom_query(self, query_str: str) -> str:\n",
        "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
        "        community_summaries = self.graph_store.get_community_summaries()\n",
        "        community_answers = [\n",
        "            self.generate_answer_from_summary(community_summary, query_str)\n",
        "            for _, community_summary in community_summaries.items()\n",
        "        ]\n",
        "\n",
        "        final_answer = self.aggregate_answers(community_answers)\n",
        "        return final_answer\n",
        "\n",
        "    def generate_answer_from_summary(self, community_summary, query):\n",
        "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
        "        prompt = (\n",
        "            f\"Given the community summary: {community_summary}, \"\n",
        "            f\"how would you answer the following query? Query: {query}\"\n",
        "        )\n",
        "        messages = [\n",
        "            ChatMessage(role=\"system\", content=prompt),\n",
        "            ChatMessage(\n",
        "                role=\"user\",\n",
        "                content=\"I need an answer based on the above information.\",\n",
        "            ),\n",
        "        ]\n",
        "        response = self.llm.chat(messages)\n",
        "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
        "        return cleaned_response\n",
        "\n",
        "    def aggregate_answers(self, community_answers):\n",
        "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
        "        # intermediate_text = \" \".join(community_answers)\n",
        "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
        "        messages = [\n",
        "            ChatMessage(role=\"system\", content=prompt),\n",
        "            ChatMessage(\n",
        "                role=\"user\",\n",
        "                content=f\"Intermediate answers: {community_answers}\",\n",
        "            ),\n",
        "        ]\n",
        "        final_response = self.llm.chat(messages)\n",
        "        cleaned_final_response = re.sub(\n",
        "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
        "        ).strip()\n",
        "        return cleaned_final_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gj25KyY_M6X"
      },
      "source": [
        "##  Build End to End GraphRAG Pipeline\n",
        "\n",
        "Now that we have defined all the necessary components, let’s construct the GraphRAG pipeline:\n",
        "\n",
        "1. Create nodes/chunks from the text.\n",
        "2. Build a PropertyGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`.\n",
        "3. Construct communities and generate a summary for each community using the graph built above.\n",
        "4. Create a `GraphRAGQueryEngine` and begin querying."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugi2cDjo_M6X"
      },
      "source": [
        "### Create nodes/ chunks from the text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bCn-LKXt_M6X"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "splitter = SentenceSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=20,\n",
        ")\n",
        "nodes = splitter.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TGKBoyxM_M6X",
        "outputId": "d31c01c5-eecd-4432-efbc-560818823356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DrMVoqs_M6X"
      },
      "source": [
        "### Build ProperGraphIndex using `GraphRAGExtractor` and `GraphRAGStore`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yih2UpCE_M6X"
      },
      "outputs": [],
      "source": [
        "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
        "-Goal-\n",
        "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
        "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
        "\n",
        "-Steps-\n",
        "1. Identify all entities. For each identified entity, extract the following information:\n",
        "- entity_name: Name of the entity, capitalized\n",
        "- entity_type: Type of the entity\n",
        "- entity_description: Comprehensive description of the entity's attributes and activities\n",
        "Format each entity as (\"entity\"$$$$<entity_name>$$$$<entity_type>$$$$<entity_description>)\n",
        "\n",
        "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
        "For each pair of related entities, extract the following information:\n",
        "- source_entity: name of the source entity, as identified in step 1\n",
        "- target_entity: name of the target entity, as identified in step 1\n",
        "- relation: relationship between source_entity and target_entity\n",
        "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
        "\n",
        "Format each relationship as (\"relationship\"$$$$<source_entity>$$$$<target_entity>$$$$<relation>$$$$<relationship_description>)\n",
        "\n",
        "3. When finished, output.\n",
        "\n",
        "-Real Data-\n",
        "######################\n",
        "text: {text}\n",
        "######################\n",
        "output:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7xkeAGVC_M6X"
      },
      "outputs": [],
      "source": [
        "entity_pattern = r'\\(\"entity\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
        "relationship_pattern = r'\\(\"relationship\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\$\\$\\$\\$\"(.+?)\"\\)'\n",
        "\n",
        "\n",
        "def parse_fn(response_str: str) -> Any:\n",
        "    entities = re.findall(entity_pattern, response_str)\n",
        "    relationships = re.findall(relationship_pattern, response_str)\n",
        "    return entities, relationships\n",
        "\n",
        "\n",
        "kg_extractor = GraphRAGExtractor(\n",
        "    llm=llm,\n",
        "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
        "    max_paths_per_chunk=2,\n",
        "    parse_fn=parse_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WQduaxdk_M6Y",
        "outputId": "a48e7f0e-cd59-44fc-f2b6-5c965b22a980",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting paths from text: 100%|██████████| 50/50 [05:55<00:00,  7.11s/it]\n",
            "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
            "Generating embeddings: 100%|██████████| 4/4 [00:01<00:00,  2.65it/s]\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import PropertyGraphIndex\n",
        "\n",
        "index = PropertyGraphIndex(\n",
        "    nodes=nodes,\n",
        "    property_graph_store=GraphRAGStore(),\n",
        "    kg_extractors=[kg_extractor],\n",
        "    show_progress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Zoqly1wQ_M6Y",
        "outputId": "36999399-daf9-4385-bc48-41ac0aee9301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntityNode(label='entity', embedding=None, properties={'relationship_description': 'Uber and Gett Taxi are competitors in the Israeli taxi and private hire market.', 'triplet_source_id': '5e2135ac-52ce-48ca-9afa-01e1948a6a78'}, name='Competition')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.nodes.values())[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZUAi5A9p_M6Y",
        "outputId": "743415db-aaa5-47d0-ff38-dd3f933b646d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Relation(label='O&G sector', source_id='Chevron', target_id='Operates in', properties={'relationship_description': 'Chevron is a company that operates in the O&G sector.', 'triplet_source_id': 'e5e34d30-54a2-4b50-ade6-2ce6c180abec'})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.relations.values())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EpGM8EAB_M6Y",
        "outputId": "11c42e1d-2186-40e1-aad4-69e120c88acf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chevron is a company that operates in the O&G sector.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "list(index.property_graph_store.graph.relations.values())[0].properties[\n",
        "    \"relationship_description\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmxBafEc_M6Y"
      },
      "source": [
        "### Build communities\n",
        "\n",
        "This will create communities and summary for each community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yOkXW3AL_M6Y",
        "outputId": "415e7dc6-6761-405b-e930-db6abb0ad335",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/graspologic/partition/leiden.py:607: UserWarning: Leiden partitions do not contain all nodes from the input graph because input graph contained isolate nodes.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "index.property_graph_store.build_communities()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvnZTzQs_M6Y"
      },
      "source": [
        "### Create QueryEngine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a8I2HXSV_M6Y"
      },
      "outputs": [],
      "source": [
        "query_engine = GraphRAGQueryEngine(\n",
        "    graph_store=index.property_graph_store, llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqy2s31E_M6Y"
      },
      "source": [
        "### Querying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YvJFAL5F_M6Y",
        "outputId": "822a59fe-38a7-4b18-822a-2ef38287cbe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The document discusses various news topics across different sectors. In the Oil & Gas industry, Chevron's Q2 consensus earnings estimates have increased despite a decrease in stock value. In politics, Sinn Féin TD John Brady and Minister for Housing Darragh O’Brien had a conflict during a debate on retained firefighters, with deputy leader Pearse Doherty requesting improved pay for the firefighters. In technology, Epic has developed the MetaHuman Animator tool, which captures an actor's facial performance and applies it to a hyperrealistic MetaHuman in the Unreal Engine. The European Commission has banned the use of TikTok Inc. by its staff due to security concerns. In the corporate world, Aidan Murray was terminated from Ryanair due to allegations of sexual harassment, and the American Fork Branch of KeyBank donated $10,000 to the Five.12 Foundation. In the smartphone industry, Vivo is set to release the X90s smartphone, which will run on the MediaTek Dimensity 9200+ SoC. In the investment sector, Nasir Qadree's company Zeal made an early investment in Esusu, and Generation Investment Management highlighted Henry Schein, Inc. in their first quarter 2023 investor letter. In sports, Manchester United and Chelsea are interested in transferring André Onana from Internazionale. In the automotive industry, Stellantis plans to idle the Belvidere Assembly Plant where the Jeep Cherokee is produced. In the banking sector, there is a reported decline in uninsured deposits at the Bank of America Corp. and across all U.S. banks. In the airline industry, JetBlue's Airbus A321 model aircraft, known as \"A Defining MoMint,\" features luxurious Mint Suites. In the cryptocurrency industry, Coinbase Global Inc. repurchased $64.5 million worth of 0.50% convertible senior notes. Finally, in the ride-hailing industry, Uber Technologies partnered with IT Taxi to expand Uber's services in new cities in Italy."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = query_engine.query(\n",
        "    \"What are the main news discussed in the document?\"\n",
        ")\n",
        "display(Markdown(f\"{response.response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SVONX0JT_M6Z",
        "outputId": "10915d93-7c44-451f-dfce-8977191a3030",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The financial sector news includes Chevron's rise in Q2 consensus earnings estimates despite a decrease in stock value, FirstEnergy's earnings results, Thomas Christl joining Morgan Stanley, KeyBank's American Fork Branch donating $10,000 to the Five.12 Foundation, Nasir Qadree's early investment in Esusu, Generation Investment Management's focus on Henry Schein, Inc., Hyatt Hotels and Supplier.io receiving the 2023 Top Supply Chain Projects award, a decline in uninsured deposits reported by Bank of America Corp. and S&P Global Inc., Coinbase Global Inc.'s repurchase of $64.5 million worth of 0.50% convertible senior notes and its legal challenges, Deutsche Bank's upgrade of Allegiant Travel from Hold to Buy, Delta Air Lines and Southwest Airlines suspending their dividends due to COVID-19, Stellantis idling the Belvidere Assembly Plant due to financial challenges, KeyBank's new branch in American Fork, Tram Nguyen's employment by Bank of America as the Global Head of Strategic and Sustainable Investments, and Scapia's partnership with Federal Bank to launch a global credit card."
          },
          "metadata": {}
        }
      ],
      "source": [
        "response = query_engine.query(\"What are news related to financial sector?\")\n",
        "display(Markdown(f\"{response.response}\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIFkt9oz_M6Z"
      },
      "source": [
        "## Future Work:\n",
        "\n",
        "This cookbook is an approximate implementation of GraphRAG. In future cookbooks, we plan to extend it as follows:\n",
        "\n",
        "1. Implement retrieval using entity description embeddings.\n",
        "2. Integrate with Neo4JPropertyGraphStore.\n",
        "3. Calculate a helpfulness score for each answer generated from the community summaries and filter out answers where the helpfulness score is zero.\n",
        "4. Perform entity disambiguation to remove duplicate entities.\n",
        "5. Implement claims or covariate information extraction, Local Search and Global Search techniques."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "llamaindex",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}